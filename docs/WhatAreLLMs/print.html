<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Print — What are Large Language Models?</title>
  <link rel="stylesheet" href="assets/base.css" />
  <link rel="stylesheet" href="assets/theme.css" />
  <link rel="stylesheet" href="assets/print.css" />
</head>
<body>
  <main class="print-deck">
    <header class="print-cover">
      <h1 class="slide-title">What are Large Language Models?</h1>
      <p class="muted">Generated by <code>build_deck.py</code>. Use your browser’s Print dialog.</p>
    </header>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">1. Intro</h2>
      </header>
      <div class="print-body">

        <div class="card">
          <strong>Course Objective:</strong> Learn how to use generative systems
          to support disciplined reasoning and problem solving.
        </div>
        <h1>Themes</h1>
        <ul class="bullets">
          <li>
            Move from raw inputs/ideas &rarr; structured info &rarr; defensible
            conclusions.
          </li>
          <li>
            Work iteratively towards a final solution, validating and testing
            along the way.
          </li>
          <li>
            Identify and document assumptions, cite evidence, verify claims.
          </li>
          <li>
            Learn about good practices when coding (or having AI code for you).
          </li>
          <li>
            Gain practice with clearly articulating your goals, methods, and
            conclusions.
          </li>
          <li>
            Clearly understand that, in its present form, "AI" is a tool and not
            a source of truth per se.
          </li>
          <li>
            Have some fun learning about neat technology and building things!
          </li>
        </ul>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">2. AI is Everywhere</h2>
      </header>
      <div class="print-body">

        <h1>You've probably heard "AI" used for:</h1>
        <ul class="bullets">
          <li>
            Chat bots, photo filters/editors/generation, recommendation feeds and targeted
            advertising.
          </li>
          <li>Self-driving vehicles and smart devices.</li>
          <li>Video games ("the AI is too easy/dumb/hard!").</li>
        </ul>
        <h1>What about Machine Learning?</h1>
        <ul class="bullets">
          <li>Is ML or AI a superset or subset of the other?</li>
          <li>
            What does it mean for a machine to "learn"? What is "intelligence",
            and what differentiates "real" from "artificial"?
          </li>
          <li>
            What do you think "AI" will mean:
            <ul class="bullets">
              <li>When you graduate?</li>
              <li>When you get a job?</li>
              <li>When you're my age (old &#x1F609;)?</li>
            </ul>
          </li>
        </ul>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">3. AI vs ML</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>Ask 10 people and you'll get 10 different answers!</h1>
          <ul class="bullets">
            <li>
              For now, let's all agree that
              <b>Artificial Intelligence</b> refers to systems that perform
              tasks we associate with intelligence (which we don't even have a
              definition for itself), whether or not they would pass a Turing
              Test.<br /><br />
              Such tasks might include:
              <ul class="bullets">
                <li>
                  Perception: E.g., Seeing, hearing, or otherwise
                  recording/processing external information so that they can do
                  things like...
                </li>
                <li>Prediction: What is likely to happen next?</li>
                <li>Decision making: What action should/will I take next?</li>
                <li>
                  Communication: Sharing knowledge, in a meaningful way, with
                  other externals (people, systems).
                </li>
              </ul>
            </li>
            <li>
              <b>Machine Learning</b>: Systems that learn patterns from data
              (e.g., Decision Trees, clustering algorithms, "simple" neural
              networks). More on that later, but I don't think any rational
              person would consider these "intelligent", even artificially!
            </li>
          </ul>
        </div>
        <figure class="slide-figure">
          <img
            class="img-md"
            alt="Placeholder figure"
            src="../assets/images/Turing_test_diagram.png"
          />
          <figcaption class="caption">
            https://en.wikipedia.org/wiki/Turing_test
          </figcaption>
        </figure>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">4. AI vs ML p2</h2>
      </header>
      <div class="print-body">

        <h1>My opinion - it's a matter of scale and human perception</h1>
        <ul class="bullets">
          <li>
            What makes (biologically, and in terms of "intelligence") a human
            different from a chimpanzee, dog, ant, octopus, elephant, whale, or
            our closer evolutionary ancestors, like <i>Homo erectus</i>?
          </li>
          <li>
            Short answer: More (and more densely packed and connected) neurons seems to have
            something to do with it!
          </li>
        </ul>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">5. AI vs ML p3</h2>
      </header>
      <div class="print-body">

        <div>
        <h1>
          What makes modern AI systems different from those in past decades (their "ancestors")?
        </h1>
        <ul class="bullets">
          <li>
            Without a doubt, research and better computational/mathematical
            techniques, but especially...
          </li>
          <li>Larger and more complex networks of (mathematical) neurons.</li>
          <li>
            Perhaps we will eventually be able to reduce the size of these
            models while retaining performance. As it stands now, scale is one
            of the most important ingredients. Data centers are huge and their energy
            requirements are on the scale of small cities.
          </li>
        </ul>
        </div>
        <div>
        <figure class="slide-figure">
          <img
            class="img-sm"
            alt="Backpropagation"
            src="../assets/images/gpt2-text.png"
          />
          <figcaption class="caption-p">
            From a course I taught in 2019. Using a GPT-2 like model, I entered the text in bold, it filled in the rest. Groundbreaking at the time, it was basically a fancy autocomplete tool that would go off the rails after a few paragraphs.
          </figcaption>
          </div>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">6. What is GenAI?</h2>
      </header>
      <div class="print-body">

        <h1>Contrasted with "traditional" AI:</h1>
        <ul class="bullets">
          <li>
            Generative AI are systems that produce new content (text/images/audio).
          </li>
          <li>Contrast with older "AI" or "ML" systems systems that typically classify or predict, such as:</li>
            <ul class="bullets">
                <li>Classifying an email as spam/not spam.</li>
                <li>Detect fraudulent transactions.</li>
                <li>Segment images, e.g., parsing satellite imagery into regions like land/water/forest/building.</li>
                <li>Predict (forecast) the next number (many flavors of regression).</li>
            </ul>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">7. What is GenAI?</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>
            What we call "Generative AI" today is based primarily on what it
            outputs:
          </h1>
          <ul class="bullets">
            <li>Text generation (ChatGPT, Gemini, Claude, etc.).</li>
            <li>Image/video generation (Veo, Sora, etc.).</li>
            <li>
              Molecular/material architectures (AlphaFold 3 - Nobel Prize
              work!).
            </li>
          </ul>
        </div>
        <div>
          <figure class="slide-figure">
            <img
              class="img-sm"
              alt="MLP Diagram"
              src="../assets/images/nobel-chem-2024.png"
            />
            <figcaption class="caption">
              https://www.nobelprize.org/prizes/chemistry/2024/press-release/
            </figcaption>
          </figure>
        </div>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">8. What are LLMs?</h2>
      </header>
      <div class="print-body">

        <h1>
          LLMs are generative models trained on LOTS of text to produce
          language.
        </h1>
        <ul class="bullets">
          <li>
            They can do things like: continue text, answer questions, summarize,
            translate, and even write computer code.
          </li>
          <li>
            Their ability to create images and audio is separate from their
            language capabilities, but many "LLMs" (e.g., ChatGPT, Gemini) now
            have these features integrated into a single interface.
          </li>
          <li>
            They are not actually "intelligent"! While they can come across as
            very human-like, this is because they have been trained on an entire
            internet of human-created content. A human, even if they devoted
            every waking moment of their life, could not even scratch the
            surface of the entirety of humanity's digital content.
          </li>
          <li>
            Their use of language, and even reasoning capabilities, can often
            seem impressive. However, when they fail, they often do so in very
            peculiar and often non-human ways.
          </li>
          <div class="card">
            <strong>Very Important:</strong> LLMs are not truth engines. They
            are language models trained to predict the next word*. They are
            getting very good at this, but do not lose sight of this fact!
          </div>
          <li>So, how did we get here?</li>
        </ul>
        <p>
          *<i
            >This is not entirely accurate, but more on that in a future
            lecture.</i
          >
        </p>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">9. History of AI</h2>
      </header>
      <div class="print-body">

        <h1>AI has meant different things at different times</h1>
        <ul class="bullets">
          <li>1950s-1960s: Early neural nets and <b>perceptrons</b></li>
          <li>
            1970s-1980s: Expert systems (explicit rule-based systems; lots of
            if-then type logic)
          </li>
          <li>
            1980s-1990s: Training neural nets becomes practical
            (<b>Backpropagation!</b>)
          </li>
          <li>2010s: Deep Learning and Big Data</li>
          <li>
            2017 to present: <b>Transformers</b> (math) &rarr; Scaling (tons of
            computing power) &rarr; Modern LLMs
          </li>
        </ul>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">10. Mark I Perceptron</h2>
      </header>
      <div class="print-body">

        <div>
          <ul class="bullets">
            <li>
              20x20 pixel "camera". Goals such as distinguishing between simple
              geometric patterns (square or circle? X or E? Object on right or
              left?).
            </li>
            <li>
              Key idea: Humans provide the algorithm and labeled examples.
              Machine tunes its own parameters (this is what is meant by a
              machine "learning").
            </li>
            <li>
              Billed as "the embryo of an electronic computer that [the Navy]
              expects will be able to walk, talk, see, write, reproduce itself
              and be conscious of its existence".
            </li>
            <li>Could not solve a simple XOR (exclusive OR) problem.</li>
          </ul>
        </div>
        <figure class="slide-figure">
          <img
            class="img-lg"
            alt="Mark I Perceptron"
            src="../assets/images/NMAH-72-361.jpg"
          />
          <figcaption class="caption">
            https://americanhistory.si.edu/collections/object/nmah_334414
          </figcaption>
        </figure>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">11. Mark I Perceptron p2</h2>
      </header>
      <div class="print-body">

        <div>
          <ul class="bullets">
            <li>It was a <b>single layer perceptron</b>.</li>
            <li>
              <b>Multilayer</b> perceptrons are still very much in use in modern
              AI.
            </li>
            <li>
              In a modern computer, each wire in this diagram is represented by
              a <b>weight</b> (just a number).
            </li>
            <li>
              Each neuron receives a signal from every neuron connected to it on
              the left, multiplied by the weight of the connection (wire) and
              all summed together.
            </li>
            <li>
              "Learning" is accomplished by providing an algorithm that tells
              the machine how to adjust its weights, based on whether it is
              correctly or incorrectly classifying its training data.
            </li>
            <li>Yes, I am oversimplifying a bit!</li>
            <li>
              Watch someone tune a perceptron by hand (Welch Labs, "ChatGPT is
              made of 100 million of these"):
              https://www.youtube.com/watch?v=l-9ALe3U-Fg
              <br />
              <p style="font-size: smaller">
                <i>(Ads from 3:20 to 4:50 and 11:35 to 13:00)</i>
              </p>
            </li>
          </ul>
        </div>
        <figure class="slide-figure">
          <img
            class="img-lg"
            alt="Mark I Perceptron"
            src="../assets/images/perceptron-markI-diagram.png"
          />
          <figcaption class="caption">
            https://anatomiesofintelligence.github.io/posts/2019-06-21-organization-mark-i-perceptron
          </figcaption>
        </figure>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">12. AI Winter</h2>
      </header>
      <div class="print-body">

        <div>
          <ul class="bullets">
            <li>
              Largely attributed to the work of Minsky and Papert, research into
              the perceptron style of AI stagnated for a decade or two.
            </li>
            <li>
              The book mathematically proved that certain classes of problems
              (such as the XOR problem) could never be learned by a system such
              as the Mark I.
            </li>
            <li>
              The book did not prove that no such machine learning was possible
              - but the next major step forward would not come until the 1980s.
            </li>
            <li>
              By the way - there's a significant structural difference between
              the images on the top and bottom of the book cover. Can you spot
              it? <i>Hint: It's not just that they are oriented differently</i>.
            </li>
          </ul>
        </div>
        <figure class="slide-figure">
          <img
            class="img-lg"
            alt="Perceptrons"
            src="../assets/images/Perceptrons_(book).jpg"
          />
          <figcaption class="caption-p">
            https://en.wikipedia.org/wiki/Perceptrons_%28book%29
          </figcaption>
        </figure>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">13. Expert Systems</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>
            Idea: Encode expert knowledge as if-then rules (a.k.a. Decision
            Trees)
          </h1>

          <ul class="bullets">
            <li>Is it cold out?</li>
            <ul class="bullets">
              <li>Yes: Is it raining?</li>
              <ul class="bullets">
                <li>Yes: Bring Umbrella</li>
                <li>No: Wear Sweater</li>
              </ul>
              <li>No: Is it Sunny?</li>
              <ul class="bullets">
                <li>Yes: Wear T-shirt</li>
                <li>No: Wear sweater</li>
              </ul>
            </ul>
            <li>Real Examples:</li>
            <ul class="bullets">
              <li>
                MYCIN: Used to diagnose blood infections and propose treatment
                plans; based on ~600 expert provided rules.
              </li>
              <li>
                XCON: Configure DEC VAX computer system orders; based on ~2,500
                expert provided rules.
              </li>
            </ul>
            <li>
              <i
                >Decision Trees are still useful and the questions/thresholds
                can be learned by an algorithm, easily in fact. Key point: DTs
                used to be "AI", now they are more like "old-school ML".</i
              >
            </li>
          </ul>
        </div>
        <figure class="slide-figure">
          <img
            class="img-md"
            alt="Decision Tree"
            src="../assets/images/DecisionTree.jpg"
          />
          <figcaption class="caption">
            https://inside-machinelearning.com/en/decision-tree-and-hyperparameters/
          </figcaption>
        </figure>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">14. Backpropagation</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>
            jk: The Chain Rule already existed (17th century; Newton, Leibniz).
          </h1>
          <ul class="bullets">
            <li>
              Going back to the original perceptron, there were two main
              problems:
            </li>
            <ol class="bullets">
              <li>The network needs more hidden ("in-between") layers.</li>
              <li>
                This can result in an explosion in the number of model
                parameters - need an efficient way to train the model (determine
                all of the model weights).
              </li>
            </ol>
            <li>
              <b>Backpropagation</b> was the key breakthrough here. Students of
              Calculus: In essence, this is an application of the Chain Rule.
            </li>
          </ul>
        </div>
        <figure class="slide-figure">
          <img
            class="img-sm"
            alt="Backpropagation"
            src="../assets/images/back.png"
          />
          <figcaption class="caption">
            https://www.r-bloggers.com/2017/05/training-neural-networks-with-backpropagation-original-publication/
          </figcaption>
        </figure>
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">15. MLP Examples</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>While MLPs are just one component of modern LLMs:</h1>
          <ul class="bullets">
            <li>
              They can be used for a variety of classification, prediction, and
              regression tasks.
            </li>
            <li>Classic example: Classifying handwritten digits.</li>
            <li>
              Watch: 3Blue1Brown, "But what is a neural network?":
              https://www.youtube.com/watch?v=aircAruvnKk
            </li>
            <li>
              Play around with one, it's fun! https://playground.tensorflow.org/
            </li>
          </ul>
        </div>
        <!-- <div> -->

        <figure class="slide-figure">
          <img
            class="img-md"
            alt="MNIST Data"
            src="../assets/images/MNIST_dataset_example.png"
          />
          <figcaption class="caption">
            Examples from the MNIST dataset.
            https://en.wikipedia.org/wiki/MNIST_database
          </figcaption>
        </figure>
        <figure class="slide-figure">
          <img
            class="img-md"
            alt="MLP Diagram"
            src="../assets/images/Example_of_a_deep_neural_network.png"
          />
          <figcaption class="caption">
            Example MLP architecture. https://en.wikipedia.org/wiki/Hidden_layer
          </figcaption>
        </figure>
        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">16. Back to LLMs</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>What does the "GPT" in ChatGPT mean?</h1>
          <ul class="bullets">
            <li>Generative: It produces new text.</li>
            <li>
              Pre-trained: As opposed to you doing the training process
              yourself.
            </li>
            <li>
              <b>Transformer</b>: This was the next major breakthrough leading
              to what we have today. It is another piece of math.
            </li>
            <li>
              Before the transformer architecture was introduced (2017) language
              models existed but were not nearly as good their modern
              counterparts.
            </li>
            <li>
              The transformer lends itself very well to
              <b>parallel processing</b>, vastly decreasing model training time.
            </li>
          </ul>
        </div>
        <!-- <div> -->
        <figure class="slide-figure">
          <img
            class="img-md"
            alt="Attention is all you need"
            src="../assets/images/attention_abstract.png"
          />
          <figcaption class="caption">
            https://arxiv.org/pdf/1706.03762
          </figcaption>
        </figure>
        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">17. What is a Transformer?</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>And what is meant by "attention"?</h1>
          <ul class="bullets">
            <li>
              Essentially, "attention" refers to the model's ability to infer
              which words are more or less important with respect to other
              words.
            </li>
            <li>
              Examples:
              <ul class="bullets">
                <li>"The cat sat on the mat because <b>it</b> was warm."</li>
                <ul class="bullets">
                  <li>What does <b>it</b> refer to?</li>
                </ul>
                <li>"John deposited money into his <b>bank</b> account."</li>
                <li>"The fisherman sat by the <b>bank</b> of the river."</li>
                <ul class="bullets">
                  <li>
                    What words help us understand the meaning of <b>bank</b> is
                    different in these examples?
                  </li>
                </ul>
              </ul>
            </li>
          </ul>
        </div>
        <!-- <div> -->
        <figure class="slide-figure">
          <img
            class="img-md"
            alt="MLP Diagram"
            src="../assets/images/transformers_PNG10.png"
          />
          <figcaption class="caption">
            Not what we are talking about!
          </figcaption>
        </figure>
        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">18. What is a Transformer, p2?</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>
            And why did you spend all that time talking about perceptrons?
          </h1>
          <ul class="bullets">
            <li>
              The blue Feed Forward blocks in the diagram are MLPs
              <i
                >(for the sake of terminology, note that all MLPs are FFNs, but
                not all FFNs are MLPs)</i
              >.
            </li>
            <li>
              GPT-3 contained 96 transformer decoders (the left half of the
              figure).
            </li>
            <li>Each decoder has an MLP as just one of its components.</li>
            <li>
              The attention layers also contain many parameters (you'll have to
              go read the paper for more detail!)
            </li>
            <li>
              For GPT-3, this works out to 175 billion parameters that need to
              be optimized during training!
            </li>
          </ul>
          <h1>
            What started off as a room-sized machine (the Mark I) is now just
            one of hundreds of the components of an LLM!
          </h1>
        </div>
        <!-- <div> -->
        <figure class="slide-figure">
          <img
            class="img-sm"
            alt="MLP Diagram"
            src="../assets/images/attention_fig1.png"
          />
          <figcaption class="caption">
            https://arxiv.org/pdf/1706.03762
          </figcaption>
        </figure>
        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">19. Where are we now?</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>Key takeaways so far:</h1>
          <ul class="bullets">
            <li>
              The meaning of AI has, and will likely continue, to change
              rapidly.
            </li>
            <li>
              What started off as a room-sized machine (the Mark I) is now just
              one of hundreds of the components of an LLM.
            </li>
            <li>
              LLMs are great at producing language, but they do not "understand"
              things like we do.
            </li>
            <li>
              Increase in scale (whether good or bad) is key to performance
              improvements. Larger models require more computational power
              (large data centers), and consume a ton of energy and water (on
              the scale of small cities).
            </li>
          </ul>
          <h1>Next up:</h1>
          <ul class="bullets">
            <li>Tokens and Context Windows</li>
            <li>Tips for getting good results from LLMs</li>
          </ul>
        </div>
        <!-- <div> -->
        <figure class="slide-figure">
          <img
            class="img-sm"
            alt="MLP Diagram"
            src="../assets/images/bike.png"
          />
          <figcaption class="caption-p">
            An image of a bike, processed by an older CNN (Convolutional Neural
            Network). Go play around at: https://deepdreamgenerator.com/
          </figcaption>
        </figure>
        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">20. Context Windows and Tokens</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>All LLMs have a limited <b>context window</b>.</h1>
          <ul class="bullets">
            <li>Context windows are measured in <b>tokens</b>.</li>
            <li>
              Tokens are like "units of text". They are typically words, parts
              of words, and punctuation.
            </li>
            <li>
              "He is running." might decompose into 5 tokens: (he, is, run,
              ning, .)
            </li>
            <li>
              Different models tokenize differently, so mileage may vary. (See
              https://tiktokenizer.vercel.app/)
            </li>
            <li>
              LLMs use the tokens in their current context window to predict the
              next token, over and over and over again.
            </li>
            <li>
              Many models implement "reasoning" steps as well, where they
              conduct an internal dialog with themselves before producing the
              final answer they give you. These tokens can also count towards
              things like usage limits and billing rates.
            </li>
            <li>
              Context windows generally range from thousands to millions of
              tokens, depending on the model.
            </li>
          </ul>
        </div>
        <!-- <div> -->

        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">21. Context Windows and Tokens, p2</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>All LLMs have a limited <b>context window</b>.</h1>
          <ul class="bullets">
            <li>
              LLMs tend to perform better when they have more context about what
              you are trying to do.
            </li>
            <li>
              The more room you give the LLM to guess, the more likely it is to
              guess incorrectly.
            </li>
            <li>
              On the other hand, and especially for very long chats (or if you
              give it many documents to analyze), the context window might fill
              up. Ever feel like the model suddenly got amnesia?
            </li>
          </ul>
          <h1>
            Learn to work iteratively and decompose your big problems into
            smaller problems.
          </h1>
          <ul class="bullets">
            <li>
              Periodically ask the LLM to summarize your chat and save its
              output. Use that summary to seed a new chat.
            </li>
            <li>Working on a big project?</li>
            <ul class="bullets">
              <li>Start by asking the LLM to help you plan the project.</li>
              <li>Work with the LLM to come up with an implementation plan.</li>
              <li>
                Use those plans to tackle the project in a sequence of separate,
                smaller steps that can each be tested/validated independently.
              </li>
            </ul>
          </ul>
        </div>
        <!-- <div> -->

        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">22. Context Windows and Tokens, p3</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>Be clear and concise.</h1>
          <ul class="bullets">
            <li>
              LLMs tend to perform better when they have more context about what
              you are trying to do.
            </li>
            <li>
              The more room you give the LLM to guess, the more likely it is to
              guess incorrectly.
            </li>
            <li>
              Provide constraints and clear goals, even including the
              format/style of the response you want:
            </li>
            <ul class="bullets">
              <li>Bad: "Can you help me improve my presentation?"</li>
              <li>
                Slightly Better: "Edit this paragraph to make it more clear and
                professional."
              </li>
              <li>
                Much Better: "Edit this paragraph so that it is more
                understandable to an audience of first-year college students
                with no programming experience. Retain the original meaning,
                keep the final version between 200-300 words, and provide 3
                bullet points explaining the most important changes you made and
                why you made them. Provide the edited paragraph first, and the
                bullet list below it.
              </li>
            </ul>
            <li>
              Even better than the last version would be to have some other
              document(s) you have provided the LLM, for example a course
              description/syllabus.
            </li>
            <li>
              If you don't like what you get, try to identify exactly what it is
              you don't like, be as clear as possible about it, and work
              iteratively - one issue at a time.
            </li>
          </ul>
        </div>
        <!-- <div> -->

        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">23. Context Windows and Tokens, p4</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>Be clear and concise.</h1>
          <ul class="bullets">
            <li>Define the task and the audience.</li>
            <li>Define the constraints (length, format, tone).</li>
            <li>
              Define success criteria: What do you think a "good" answer should
              include?
            </li>
          </ul>
          <h1>
            Be aware of model variability. LLMs are not deterministic. Given the
            same prompt multiple times, you will get different answers.
          </h1>
          <ul class="bullets">
            <li>You can also use this fact to check/refine your prompts.</li>
            <li>Give the same prompt in different chats, compare results.</li>
            <li>Give the same prompt to a different LLM, compare results.</li>
          </ul>
        </div>
        <!-- <div> -->

        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">24. Context Windows and Tokens, p5</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>Have a disciplined workflow:</h1>
          <ul class="bullets">
            <li>Start with a draft</li>
            <li>Check the results</li>
            <li>Re-prompt, modify context if needed, and repeat</li>
          </ul>
          <h1>Things to ask yourself:</h1>
          <ul class="bullets">
            <li>What are the assumptions?</li>
            <li>What evidence supports each claim?</li>
            <li>What would falsify this (what would change my mind)?</li>
          </ul>
        </div>
        <!-- <div> -->

        <!-- </div> -->
      
      </div>
    </section>

    <section class="print-slide">
      <header class="print-header">
        <h2 class="print-title">25. Citing AI</h2>
      </header>
      <div class="print-body">

        <div>
          <h1>How to properly cite AI:</h1>
          <ul class="bullets">
            <li>
              For factual claims, insert actual references (not "ChatGPT said
              so").
            </li>
            <li>
              Be aware that LLMs can hallucinate sources! Make sure to check
              them yourself.
            </li>
            <li>
              If using AI to write code, be honest about what you used it for.
              Do not simply use AI generated code without testing it and making
              an honest attempt to understand it.
            </li>
          </ul>
          <h1>Things to ask yourself:</h1>
          <ul class="bullets">
            <li>What are the assumptions? Write them down explicitly.</li>
            <li>
              What evidence supports each claim? What tests did I do to make
              sure the code works/answers are correct?
            </li>
            <li>What would falsify this (what would change my mind)?</li>
          </ul>
        </div>
        <!-- <div> -->

        <!-- </div> -->
      
      </div>
    </section>
  </main>

  <script defer src="assets/math-katex-setup.js"></script>
</body>
</html>
